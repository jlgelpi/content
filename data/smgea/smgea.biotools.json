{
    "additionDate": "2021-01-18T12:36:36Z",
    "biotoolsCURIE": "biotools:smgea",
    "biotoolsID": "smgea",
    "confidence_flag": "tool",
    "description": "A New Ensemble Adversarial Attack Powered by Long-Term Gradient Memories.\n\nDeep neural networks are vulnerable to adversarial attacks. More importantly, some adversarial examples crafted against an ensemble of source models transfer to other target models and, thus, pose a security threat to black-box applications (when attackers have no access to the target models). Current transfer-based ensemble attacks, however, only consider a limited number of source models to craft an adversarial example and, thus, obtain poor transferability. Besides, recent query-based black-box attacks, which require numerous queries to the target model, not only come under suspicion by the target model but also cause expensive query cost. In this article, we propose a novel transfer-based black-box attack, dubbed serial-minigroup-ensemble-attack (SMGEA)",
    "editPermission": {
        "type": "private"
    },
    "homepage": "https://github.com/CZHQuality/AAA-Pix2pix",
    "lastUpdate": "2021-02-19T16:32:51.777212Z",
    "name": "SMGEA",
    "owner": "zsmag19",
    "publication": [
        {
            "doi": "10.1109/TNNLS.2020.3039295",
            "pmid": "33296311"
        }
    ],
    "topic": [
        {
            "term": "Machine learning",
            "uri": "http://edamontology.org/topic_3474"
        },
        {
            "term": "Transcription factors and regulatory sites",
            "uri": "http://edamontology.org/topic_0749"
        }
    ]
}